{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLfHxPMjuwuj"
   },
   "source": [
    "# Comparing AWS Bedrock Foundation Model Outputs - Claude Sonnet vs. Claude Haiku\n",
    "* Notebook by Adam Lang\n",
    "* Date: 2/27/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRmVSPMW4RaP"
   },
   "source": [
    "# Overview\n",
    "1. Testing head to head the outputs of Claude-3.5-Sonnet vs. Claude-3-Haiku. \n",
    "2. Generating keywords for a list of given input keywords. This would be similar to a nearest neighbors search so not direct synonyms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NszSKl719gS"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yWVLVRic-s4j"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import asyncio\n",
    "import random\n",
    "import pandas as pd \n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import display, Markdown\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Bedrock client\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='<your region here>'  # Replace with your region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init boto session\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "print(f\"Access Key: {credentials.access_key}\")\n",
    "print(f\"Secret Key: {'*' * len(credentials.secret_key)}\")\n",
    "print(f\"Region: {session.region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to run API call to Claude on AWS Bedrock\n",
    "* We now generate related words instead of just synonyms.\n",
    "* We can now process a list of keywords and generate related words for each.\n",
    "* This also includes a built-in method to compare the outputs of `Claude-3.5-Sonnet` and `Claude-3 Haiku`.\n",
    "* There are also comparison metrics, which we can extend in the `compare_models` method. Here are some suggestions for additional metrics:\n",
    "    1. Token count: You can implement a function to count tokens in the responses.\n",
    "    2. Response time: Measure the time taken by each model to generate responses.\n",
    "    3. Unique words: Count the number of unique words in each model's output.\n",
    "    4. Semantic similarity: Use a pre-trained word embedding model (e.g., Word2Vec, GloVe) to calculate the average semantic similarity between the input keyword and the generated words.\n",
    "    5. Part-of-speech diversity: Analyze the diversity of parts of speech in the generated words.\n",
    "    6. Sentiment analysis: Compare the sentiment of the generated words between models.\n",
    "\n",
    "\n",
    "* Notes:\n",
    "1. You can change the `n`, right now i have it set to 5. If you want to change it go to this method in the class:\n",
    "   * `async def get_synonyms_claude(self, word, n=5):`\n",
    "2. I set the model `temperature` at 0.5 to introduce some probabilistic or randomness but you can reduce this closer to 0 to make it more deterministic and move it closer to 1 to make it more diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Related Words from both Claude-3.5-Sonnet and Claude-3-Haiku\n",
    "* We will demo Claude-3 Haiku on Bedrock and then we will compare it to Sonnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## related words generator\n",
    "class RelatedWordsGenerator:\n",
    "    def __init__(self, region_name='<your region here>'):\n",
    "        self.bedrock = boto3.client('bedrock-runtime', region_name=region_name)\n",
    "        self.claude_sonnet = 'anthropic.claude-3-sonnet-20240229-v1:0' ## sonnet model\n",
    "        self.claude_haiku = 'anthropic.claude-3-haiku-20240307-v1:0' ## haiku model\n",
    "\n",
    "\n",
    "    async def invoke_with_retry(self, model_id, body, max_retries=5, initial_delay=1):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = await asyncio.to_thread(\n",
    "                    self.bedrock.invoke_model,\n",
    "                    modelId=model_id,\n",
    "                    body=body\n",
    "                )\n",
    "                return response\n",
    "            except ClientError as e:\n",
    "                if e.response['Error']['Code'] == 'ThrottlingException':\n",
    "                    delay = (2 ** attempt) + random.uniform(0, 1)\n",
    "                    print(f\"Request throttled. Retrying in {delay:.2f} seconds...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                else:\n",
    "                    raise\n",
    "        raise Exception(\"Max retries reached\")\n",
    "\n",
    "\n",
    "    async def get_related_words(self, word, n=10, model_id=None):\n",
    "        if model_id is None:\n",
    "            model_id = self.claude_sonnet\n",
    "\n",
    "        prompt = f\"\"\"Generate {n} related words for the keyword \"{word}\".\n",
    "        Include synonyms and words that might be found in a nearest neighbor search.\n",
    "        Provide only the related words as a comma-separated list, without any additional text or explanation.\"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 300,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 1,\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            response = await self.invoke_with_retry(model_id, body)\n",
    "            response_body = json.loads(response['body'].read())\n",
    "            related_words = response_body['content'][0]['text'].strip().split(', ')\n",
    "            return related_words[:n]  # Ensure we return at most n related words\n",
    "        except Exception as e:\n",
    "            print(f\"Error in API call: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "    async def process_keyword_list(self, keywords, n=10, model_id=None):\n",
    "        results = {}\n",
    "        for keyword in keywords:\n",
    "            related_words = await self.get_related_words(keyword, n, model_id)\n",
    "            results[keyword] = related_words\n",
    "        return results\n",
    "\n",
    "\n",
    "    async def display_related_words(self, results):\n",
    "        for keyword, related_words in results.items():\n",
    "            markdown_output = f\"## Related words for \\\"{keyword}\\\"\\n\\n\" + \"\\n\".join(f\"- {word}\" for word in related_words)\n",
    "            display(Markdown(markdown_output))\n",
    "\n",
    "    async def generate_comparisons(self, keywords, n=10):\n",
    "        sonnet_results = await self.process_keyword_list(keywords, n, self.claude_sonnet)\n",
    "        haiku_results = await self.process_keyword_list(keywords, n, self.claude_haiku)\n",
    "        return sonnet_results, haiku_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize RelatedWordsGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init keyword generator\n",
    "generator = RelatedWordsGenerator()\n",
    "## setup list of keywords\n",
    "keywords = [\"Integrity\", \"Innovation\", \"Customer Focus\", \n",
    "            \"Excellence\", \"Collaboration\", \"Respect\", \n",
    "            \"Accountability\", \"Sustainability\", \"Agility\", \n",
    "            \"Community\", \"AI\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Keyword   Model                 Related Word  Word Index\n",
      "0    Integrity  Sonnet                      honesty           1\n",
      "1    Integrity   Haiku                      Honesty           1\n",
      "2    Integrity  Sonnet                       ethics           2\n",
      "3    Integrity   Haiku                     Morality           2\n",
      "4    Integrity  Sonnet                   principles           3\n",
      "..         ...     ...                          ...         ...\n",
      "215         AI   Haiku  natural language processing           8\n",
      "216         AI  Sonnet                deep learning           9\n",
      "217         AI   Haiku                     big data           9\n",
      "218         AI  Sonnet                    cognitive          10\n",
      "219         AI   Haiku                    analytics          10\n",
      "\n",
      "[220 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## function to create dataframe from LLM results dictionary \n",
    "def create_dataframe(sonnet_results, haiku_results):\n",
    "    data = []\n",
    "    for keyword in sonnet_results.keys():\n",
    "        sonnet_words = sonnet_results[keyword]\n",
    "        haiku_words = haiku_results[keyword]\n",
    "        \n",
    "        # Ensure both lists have the same length\n",
    "        max_length = max(len(sonnet_words), len(haiku_words))\n",
    "        sonnet_words = sonnet_words + [''] * (max_length - len(sonnet_words))\n",
    "        haiku_words = haiku_words + [''] * (max_length - len(haiku_words))\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            data.append({\n",
    "                'Keyword': keyword,\n",
    "                'Model': 'Sonnet',\n",
    "                'Related Word': sonnet_words[i],\n",
    "                'Word Index': i + 1\n",
    "            })\n",
    "            data.append({\n",
    "                'Keyword': keyword,\n",
    "                'Model': 'Haiku',\n",
    "                'Related Word': haiku_words[i],\n",
    "                'Word Index': i + 1\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate the results\n",
    "sonnet_results, haiku_results = await generator.generate_comparisons(keywords)\n",
    "\n",
    "# Create the output DataFrame\n",
    "df = create_dataframe(sonnet_results, haiku_results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# You can also save the results to a CSV file if needed\n",
    "# df.to_csv('related_words_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Model</th>\n",
       "      <th>Related Word</th>\n",
       "      <th>Word Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>honesty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>Haiku</td>\n",
       "      <td>Honesty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>ethics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>Haiku</td>\n",
       "      <td>Morality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Integrity</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>principles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Keyword   Model Related Word  Word Index\n",
       "0  Integrity  Sonnet      honesty           1\n",
       "1  Integrity   Haiku      Honesty           1\n",
       "2  Integrity  Sonnet       ethics           2\n",
       "3  Integrity   Haiku     Morality           2\n",
       "4  Integrity  Sonnet   principles           3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Sonnet_1          Sonnet_2  \\\n",
      "Keyword                                                     \n",
      "AI              artificial intelligence  machine learning   \n",
      "Accountability           Responsibility     Answerability   \n",
      "Agility                      Nimbleness         Dexterity   \n",
      "Collaboration                  Teamwork       Cooperation   \n",
      "Community                  neighborhood           society   \n",
      "Customer Focus           Client-centric   User Experience   \n",
      "Excellence                   Perfection           Quality   \n",
      "Innovation                   Creativity         Invention   \n",
      "Integrity                       honesty            ethics   \n",
      "Respect                           honor           dignity   \n",
      "Sustainability              Environment      eco-friendly   \n",
      "\n",
      "                           Sonnet_3               Sonnet_4  \\\n",
      "Keyword                                                      \n",
      "AI                  neural networks             algorithms   \n",
      "Accountability            Liability            Culpability   \n",
      "Agility                   Swiftness              Quickness   \n",
      "Collaboration           Partnership           Coordination   \n",
      "Community                     group             collective   \n",
      "Customer Focus  Service Orientation  Consumer Satisfaction   \n",
      "Excellence              Superiority            Distinction   \n",
      "Innovation                Ingenuity            Advancement   \n",
      "Integrity                principles                 morals   \n",
      "Respect                      esteem             admiration   \n",
      "Sustainability                green              renewable   \n",
      "\n",
      "                           Sonnet_5      Sonnet_6        Sonnet_7  \\\n",
      "Keyword                                                             \n",
      "AI                         robotics    automation       computing   \n",
      "Accountability           Obligation  Transparency      Governance   \n",
      "Agility                 Athleticism   Flexibility  Responsiveness   \n",
      "Collaboration               Synergy    Collective           Unity   \n",
      "Community                    people    fellowship           unity   \n",
      "Customer Focus  Audience Engagement  People-First  Customer Needs   \n",
      "Excellence                 Eminence       Mastery      Brilliance   \n",
      "Innovation            Modernization       Novelty  Transformation   \n",
      "Integrity                    values     character          virtue   \n",
      "Respect                   reverence     deference    appreciation   \n",
      "Sustainability         conservation     recycling      ecological   \n",
      "\n",
      "                       Sonnet_8       Sonnet_9       Sonnet_10  \\\n",
      "Keyword                                                          \n",
      "AI                 data science  deep learning       cognitive   \n",
      "Accountability      Stewardship      Oversight      Ownership.   \n",
      "Agility         Maneuverability       Spryness       Alacrity.   \n",
      "Collaboration          Alliance  Participation  Communication.   \n",
      "Community          togetherness        kinship      belonging.   \n",
      "Customer Focus  Personalization        Loyalty        Empathy.   \n",
      "Excellence          Exceptional    Outstanding     Preeminent.   \n",
      "Innovation           Disruption   Breakthrough     Pioneering.   \n",
      "Integrity         righteousness    uprightness        probity.   \n",
      "Respect                courtesy         regard     veneration.   \n",
      "Sustainability        longevity      endurance     resilience.   \n",
      "\n",
      "                         Haiku_1          Haiku_2          Haiku_3  \\\n",
      "Keyword                                                              \n",
      "AI              machine learning       algorithms  neural networks   \n",
      "Accountability    Responsibility        Liability    Answerability   \n",
      "Agility               Nimbleness        Dexterity        Quickness   \n",
      "Collaboration           Teamwork      Partnership      Cooperation   \n",
      "Community                Society     Neighborhood            Group   \n",
      "Customer Focus    Client-centric  Client-oriented  Personalization   \n",
      "Excellence            Perfection      Superiority          Mastery   \n",
      "Innovation            Creativity        Invention       Disruption   \n",
      "Integrity                Honesty         Morality           Ethics   \n",
      "Respect                   Esteem       Admiration        Deference   \n",
      "Sustainability      Eco-friendly        Renewable     Conservation   \n",
      "\n",
      "                       Haiku_4       Haiku_5           Haiku_6  \\\n",
      "Keyword                                                          \n",
      "AI                  automation      robotics     deep learning   \n",
      "Accountability      Obligation          Duty      Transparency   \n",
      "Agility            Flexibility     Swiftness          Mobility   \n",
      "Collaboration     Coordination       Synergy       Interaction   \n",
      "Community           Collective  Congregation       Association   \n",
      "Customer Focus  Responsiveness       Empathy      Satisfaction   \n",
      "Excellence         Distinction   Preeminence        Brilliance   \n",
      "Innovation      Transformation   Advancement     Modernization   \n",
      "Integrity               Virtue     Principle         Sincerity   \n",
      "Respect              Reverence        Regard             Honor   \n",
      "Sustainability      Resilience   Stewardship  Environmentalism   \n",
      "\n",
      "                        Haiku_7                      Haiku_8  \\\n",
      "Keyword                                                        \n",
      "AI              computer vision  natural language processing   \n",
      "Accountability      Reliability                    Integrity   \n",
      "Agility               Alertness               Responsiveness   \n",
      "Collaboration          Alliance                   Networking   \n",
      "Community            Fellowship                    Communion   \n",
      "Customer Focus          Loyalty                   Engagement   \n",
      "Excellence              Prowess                     Eminence   \n",
      "Innovation         Breakthrough                    Ingenuity   \n",
      "Integrity       Trustworthiness                  Uprightness   \n",
      "Respect           Consideration                 Appreciation   \n",
      "Sustainability            Green             Circular economy   \n",
      "\n",
      "                                Haiku_9          Haiku_10  \n",
      "Keyword                                                    \n",
      "AI                             big data         analytics  \n",
      "Accountability                Ownership        Commitment  \n",
      "Agility                      Adroitness   Maneuverability  \n",
      "Collaboration             Collaboration      Joint Effort  \n",
      "Community                   Affiliation       Camaraderie  \n",
      "Customer Focus             Needs-driven  Service-oriented  \n",
      "Excellence                    Expertise       Proficiency  \n",
      "Innovation                  Originality        Pioneering  \n",
      "Integrity                   Credibility    Accountability  \n",
      "Respect                        Courtesy           Dignity  \n",
      "Sustainability  Sustainable development      Responsible.  \n"
     ]
    }
   ],
   "source": [
    "## results as a pandas pivot table\n",
    "def create_pivot_table(sonnet_results, haiku_results):\n",
    "    data = []\n",
    "    for keyword in sonnet_results.keys():\n",
    "        sonnet_words = sonnet_results[keyword]\n",
    "        haiku_words = haiku_results[keyword]\n",
    "        \n",
    "        # Ensure both lists have the same length\n",
    "        max_length = max(len(sonnet_words), len(haiku_words))\n",
    "        sonnet_words = sonnet_words + [''] * (max_length - len(sonnet_words))\n",
    "        haiku_words = haiku_words + [''] * (max_length - len(haiku_words))\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            data.append({\n",
    "                'Keyword': keyword,\n",
    "                'Sonnet': sonnet_words[i],\n",
    "                'Haiku': haiku_words[i],\n",
    "                'Word Index': i + 1\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create pivot table\n",
    "    pivot_df = df.pivot(index='Keyword', columns='Word Index', values=['Sonnet', 'Haiku'])\n",
    "    \n",
    "    # Flatten column multi-index\n",
    "    pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
    "    \n",
    "    return pivot_df\n",
    "\n",
    "# # Generate the results\n",
    "# sonnet_results, haiku_results = await generator.generate_comparisons(keywords)\n",
    "\n",
    "# Create the pivot table\n",
    "pivot_df = create_pivot_table(sonnet_results, haiku_results)\n",
    "\n",
    "# Display the pivot table\n",
    "print(pivot_df)\n",
    "\n",
    "# You can also save it to a CSV file if needed\n",
    "# pivot_df.to_csv('related_words_comparison_pivot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.T.to_csv('keywords_claude_vs_haiku.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compare Sonnet vs. Haiku model outputs\n",
    "* For measuring token counts, the exact tokenization method used by Claude models isn't publicly available. \n",
    "* Anthropic, the company behind Claude, hasn't released an official tokenizer for their models. They often suggest using tiktoken with the \"cl100k_base\" encoding as the closest approximation so we will use that to count tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture \n",
    "!pip install sentence-transformers nltk scikit-learn tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sagemaker-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/sagemaker-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## download nltk modules\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## additional imports \n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "## NLP imports\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tiktoken ## we will use this instead of the nltk tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model comparison with totals\n",
    "class ModelComparator:\n",
    "    def __init__(self):\n",
    "        self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.claude_sonnet = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "        self.claude_haiku = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def estimate_tokens(self, text):\n",
    "        return len(self.tokenizer.encode(text))\n",
    "\n",
    "    def calculate_token_cost(self, token_count, model):\n",
    "        rates = {\n",
    "            self.claude_sonnet: 0.00001563,\n",
    "            self.claude_haiku: 0.00000735\n",
    "        }\n",
    "        return token_count * rates[model]\n",
    "\n",
    "    def calculate_cosine_similarity(self, text1, text2):\n",
    "        embedding1 = self.sentence_transformer.encode([text1])[0]\n",
    "        embedding2 = self.sentence_transformer.encode([text2])[0]\n",
    "        return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "\n",
    "    def compare_outputs(self, sonnet_results, haiku_results):\n",
    "        comparison_results = {}\n",
    "        total_sonnet_tokens = 0\n",
    "        total_haiku_tokens = 0\n",
    "        total_sonnet_cost = 0\n",
    "        total_haiku_cost = 0\n",
    "        total_cosine_similarity = 0\n",
    "\n",
    "        for keyword in sonnet_results.keys():\n",
    "            sonnet_words = sonnet_results[keyword]\n",
    "            haiku_words = haiku_results[keyword]\n",
    "\n",
    "            sonnet_text = \" \".join(sonnet_words)\n",
    "            haiku_text = \" \".join(haiku_words)\n",
    "\n",
    "            # Estimated token counts\n",
    "            sonnet_estimated_tokens = self.estimate_tokens(sonnet_text)\n",
    "            haiku_estimated_tokens = self.estimate_tokens(haiku_text)\n",
    "\n",
    "            # Estimated Token count and cost\n",
    "            sonnet_cost = self.calculate_token_cost(sonnet_estimated_tokens, self.claude_sonnet)\n",
    "            haiku_cost = self.calculate_token_cost(haiku_estimated_tokens, self.claude_haiku)\n",
    "\n",
    "            # Cosine similarity\n",
    "            cosine_sim = self.calculate_cosine_similarity(sonnet_text, haiku_text)\n",
    "\n",
    "            # Update totals\n",
    "            total_sonnet_tokens += sonnet_estimated_tokens\n",
    "            total_haiku_tokens += haiku_estimated_tokens\n",
    "            total_sonnet_cost += sonnet_cost\n",
    "            total_haiku_cost += haiku_cost\n",
    "            total_cosine_similarity += cosine_sim\n",
    "\n",
    "            comparison_results[keyword] = {\n",
    "                \"sonnet\": {\n",
    "                    \"words\": sonnet_words,\n",
    "                    \"estimated_tokens\": sonnet_estimated_tokens,\n",
    "                    \"estimated_cost\": sonnet_cost,\n",
    "                },\n",
    "                \"haiku\": {\n",
    "                    \"words\": haiku_words,\n",
    "                    \"estimated_tokens\": haiku_estimated_tokens,\n",
    "                    \"estimated_cost\": haiku_cost,\n",
    "                },\n",
    "                \"cosine_similarity\": cosine_sim\n",
    "            }\n",
    "\n",
    "        num_keywords = len(sonnet_results)\n",
    "        avg_cosine_similarity = total_cosine_similarity / num_keywords\n",
    "\n",
    "        summary = {\n",
    "            \"total_sonnet_tokens\": total_sonnet_tokens,\n",
    "            \"total_haiku_tokens\": total_haiku_tokens,\n",
    "            \"total_sonnet_cost\": total_sonnet_cost,\n",
    "            \"total_haiku_cost\": total_haiku_cost,\n",
    "            \"avg_cosine_similarity\": avg_cosine_similarity\n",
    "        }\n",
    "\n",
    "        return comparison_results, summary\n",
    "\n",
    "    def display_comparison(self, comparison_results, summary):\n",
    "        print(\"Detailed Comparison:\")\n",
    "        for keyword, results in comparison_results.items():\n",
    "            print(f\"\\nKeyword: {keyword}\")\n",
    "            print(f\"Sonnet words: {results['sonnet']['words']}\")\n",
    "            print(f\"Haiku words: {results['haiku']['words']}\")\n",
    "            print(f\"Sonnet estimated tokens: {results['sonnet']['estimated_tokens']}\")\n",
    "            print(f\"Haiku estimated tokens: {results['haiku']['estimated_tokens']}\")\n",
    "            print(f\"Sonnet estimated cost: ${results['sonnet']['estimated_cost']:.6f}\")\n",
    "            print(f\"Haiku estimated cost: ${results['haiku']['estimated_cost']:.6f}\")\n",
    "            print(f\"Cosine similarity: {results['cosine_similarity']:.4f}\")\n",
    "\n",
    "        print(\"\\nSummary:\")\n",
    "        print(f\"Total Sonnet tokens: {summary['total_sonnet_tokens']}\")\n",
    "        print(f\"Total Haiku tokens: {summary['total_haiku_tokens']}\")\n",
    "        print(f\"Total Sonnet cost: ${summary['total_sonnet_cost']:.6f}\")\n",
    "        print(f\"Total Haiku cost: ${summary['total_haiku_cost']:.6f}\")\n",
    "        print(f\"Average cosine similarity: {summary['avg_cosine_similarity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Comparison:\n",
      "\n",
      "Keyword: Integrity\n",
      "Sonnet words: ['honesty', 'ethics', 'principles', 'morals', 'values', 'character', 'virtue', 'righteousness', 'uprightness', 'probity.']\n",
      "Haiku words: ['Honesty', 'Morality', 'Ethics', 'Virtue', 'Principle', 'Sincerity', 'Trustworthiness', 'Uprightness', 'Credibility', 'Accountability']\n",
      "Sonnet estimated tokens: 15\n",
      "Haiku estimated tokens: 23\n",
      "Sonnet estimated cost: $0.000234\n",
      "Haiku estimated cost: $0.000169\n",
      "Cosine similarity: 0.7981\n",
      "\n",
      "Keyword: Innovation\n",
      "Sonnet words: ['Creativity', 'Invention', 'Ingenuity', 'Advancement', 'Modernization', 'Novelty', 'Transformation', 'Disruption', 'Breakthrough', 'Pioneering.']\n",
      "Haiku words: ['Creativity', 'Invention', 'Disruption', 'Transformation', 'Advancement', 'Modernization', 'Breakthrough', 'Ingenuity', 'Originality', 'Pioneering']\n",
      "Sonnet estimated tokens: 21\n",
      "Haiku estimated tokens: 20\n",
      "Sonnet estimated cost: $0.000328\n",
      "Haiku estimated cost: $0.000147\n",
      "Cosine similarity: 0.9310\n",
      "\n",
      "Keyword: Customer Focus\n",
      "Sonnet words: ['Client-centric', 'User Experience', 'Service Orientation', 'Consumer Satisfaction', 'Audience Engagement', 'People-First', 'Customer Needs', 'Personalization', 'Loyalty', 'Empathy.']\n",
      "Haiku words: ['Client-centric', 'Client-oriented', 'Personalization', 'Responsiveness', 'Empathy', 'Satisfaction', 'Loyalty', 'Engagement', 'Needs-driven', 'Service-oriented']\n",
      "Sonnet estimated tokens: 22\n",
      "Haiku estimated tokens: 18\n",
      "Sonnet estimated cost: $0.000344\n",
      "Haiku estimated cost: $0.000132\n",
      "Cosine similarity: 0.8482\n",
      "\n",
      "Keyword: Excellence\n",
      "Sonnet words: ['Perfection', 'Quality', 'Superiority', 'Distinction', 'Eminence', 'Mastery', 'Brilliance', 'Exceptional', 'Outstanding', 'Preeminent.']\n",
      "Haiku words: ['Perfection', 'Superiority', 'Mastery', 'Distinction', 'Preeminence', 'Brilliance', 'Prowess', 'Eminence', 'Expertise', 'Proficiency']\n",
      "Sonnet estimated tokens: 19\n",
      "Haiku estimated tokens: 21\n",
      "Sonnet estimated cost: $0.000297\n",
      "Haiku estimated cost: $0.000154\n",
      "Cosine similarity: 0.8464\n",
      "\n",
      "Keyword: Collaboration\n",
      "Sonnet words: ['Teamwork', 'Cooperation', 'Partnership', 'Coordination', 'Synergy', 'Collective', 'Unity', 'Alliance', 'Participation', 'Communication.']\n",
      "Haiku words: ['Teamwork', 'Partnership', 'Cooperation', 'Coordination', 'Synergy', 'Interaction', 'Alliance', 'Networking', 'Collaboration', 'Joint Effort']\n",
      "Sonnet estimated tokens: 14\n",
      "Haiku estimated tokens: 15\n",
      "Sonnet estimated cost: $0.000219\n",
      "Haiku estimated cost: $0.000110\n",
      "Cosine similarity: 0.7999\n",
      "\n",
      "Keyword: Respect\n",
      "Sonnet words: ['honor', 'dignity', 'esteem', 'admiration', 'reverence', 'deference', 'appreciation', 'courtesy', 'regard', 'veneration.']\n",
      "Haiku words: ['Esteem', 'Admiration', 'Deference', 'Reverence', 'Regard', 'Honor', 'Consideration', 'Appreciation', 'Courtesy', 'Dignity']\n",
      "Sonnet estimated tokens: 14\n",
      "Haiku estimated tokens: 20\n",
      "Sonnet estimated cost: $0.000219\n",
      "Haiku estimated cost: $0.000147\n",
      "Cosine similarity: 0.9231\n",
      "\n",
      "Keyword: Accountability\n",
      "Sonnet words: ['Responsibility', 'Answerability', 'Liability', 'Culpability', 'Obligation', 'Transparency', 'Governance', 'Stewardship', 'Oversight', 'Ownership.']\n",
      "Haiku words: ['Responsibility', 'Liability', 'Answerability', 'Obligation', 'Duty', 'Transparency', 'Reliability', 'Integrity', 'Ownership', 'Commitment']\n",
      "Sonnet estimated tokens: 18\n",
      "Haiku estimated tokens: 15\n",
      "Sonnet estimated cost: $0.000281\n",
      "Haiku estimated cost: $0.000110\n",
      "Cosine similarity: 0.7975\n",
      "\n",
      "Keyword: Sustainability\n",
      "Sonnet words: ['Environment', 'eco-friendly', 'green', 'renewable', 'conservation', 'recycling', 'ecological', 'longevity', 'endurance', 'resilience.']\n",
      "Haiku words: ['Eco-friendly', 'Renewable', 'Conservation', 'Resilience', 'Stewardship', 'Environmentalism', 'Green', 'Circular economy', 'Sustainable development', 'Responsible.']\n",
      "Sonnet estimated tokens: 12\n",
      "Haiku estimated tokens: 20\n",
      "Sonnet estimated cost: $0.000188\n",
      "Haiku estimated cost: $0.000147\n",
      "Cosine similarity: 0.6637\n",
      "\n",
      "Keyword: Agility\n",
      "Sonnet words: ['Nimbleness', 'Dexterity', 'Swiftness', 'Quickness', 'Athleticism', 'Flexibility', 'Responsiveness', 'Maneuverability', 'Spryness', 'Alacrity.']\n",
      "Haiku words: ['Nimbleness', 'Dexterity', 'Quickness', 'Flexibility', 'Swiftness', 'Mobility', 'Alertness', 'Responsiveness', 'Adroitness', 'Maneuverability']\n",
      "Sonnet estimated tokens: 29\n",
      "Haiku estimated tokens: 26\n",
      "Sonnet estimated cost: $0.000453\n",
      "Haiku estimated cost: $0.000191\n",
      "Cosine similarity: 0.8386\n",
      "\n",
      "Keyword: Community\n",
      "Sonnet words: ['neighborhood', 'society', 'group', 'collective', 'people', 'fellowship', 'unity', 'togetherness', 'kinship', 'belonging.']\n",
      "Haiku words: ['Society', 'Neighborhood', 'Group', 'Collective', 'Congregation', 'Association', 'Fellowship', 'Communion', 'Affiliation', 'Camaraderie']\n",
      "Sonnet estimated tokens: 16\n",
      "Haiku estimated tokens: 17\n",
      "Sonnet estimated cost: $0.000250\n",
      "Haiku estimated cost: $0.000125\n",
      "Cosine similarity: 0.6620\n",
      "\n",
      "Keyword: AI\n",
      "Sonnet words: ['artificial intelligence', 'machine learning', 'neural networks', 'algorithms', 'robotics', 'automation', 'computing', 'data science', 'deep learning', 'cognitive']\n",
      "Haiku words: ['machine learning', 'algorithms', 'neural networks', 'automation', 'robotics', 'deep learning', 'computer vision', 'natural language processing', 'big data', 'analytics']\n",
      "Sonnet estimated tokens: 16\n",
      "Haiku estimated tokens: 17\n",
      "Sonnet estimated cost: $0.000250\n",
      "Haiku estimated cost: $0.000125\n",
      "Cosine similarity: 0.7367\n",
      "\n",
      "Summary:\n",
      "Total Sonnet tokens: 196\n",
      "Total Haiku tokens: 212\n",
      "Total Sonnet cost: $0.003063\n",
      "Total Haiku cost: $0.001558\n",
      "Average cosine similarity: 0.8041\n"
     ]
    }
   ],
   "source": [
    "## get results\n",
    "comparator = ModelComparator()\n",
    "comparison_results, summary = comparator.compare_outputs(sonnet_results, haiku_results)\n",
    "\n",
    "# Display the detailed comparison and summary\n",
    "comparator.display_comparison(comparison_results, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
