{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a2ada9-e758-463d-b035-8a2a5d27dccb",
   "metadata": {},
   "source": [
    "# Generative Psuedo Labeling with google/gemma-2-9b-it & Classification of \"Work Behaviors and Skills\"\n",
    "* Notebook by Adam Lang\n",
    "* Date: 2/12/2025\n",
    "\n",
    "# Overview\n",
    "* The goal of this notebook is to extract \"Work Behaviors\" and \"Skills\" from a dataset. \n",
    "\n",
    "\n",
    "# Workflow\n",
    "* We will implement chain-of-thought prompting with Gemma2-9b-It LLM and extract \"behaviors\" and \"skills\" from a pre-processed CSV file that includes an \"english_message\" column which is the translated non-english messages to english.\n",
    "* Originally I tried to use Claude-3.5-Sonnet via AWS Bedrock but the API calls were too frequent due to my limited access to Bedrock. So we will try and use Gemma2-9b-It from hugging face open source.\n",
    "* I will then use the LLM to perform Generative Pseudo Labeling where it will generate a label for each behavior and skill so we can build a pseudo classification on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d04b4-5b5a-4ba7-aa7f-29279c761fbe",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7a9086-7235-47ce-b0a9-80a7031d4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install transformers torch accelerate bitsandbytes tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9235492-a6ff-4baa-8d5e-75f20f4b2b4d",
   "metadata": {},
   "source": [
    "# Code Needed for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dad488-0cd8-4d40-b76f-9375d0d190d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df820684-da38-4c89-b557-a6275d07861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install --upgrade pandas fsspec # sagemaker dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10835fae-fa51-4e2b-b54a-67f67e9f3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install seaborn\n",
    "!pip install s3fs #sagemaker dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a1e5b4-e736-4a42-9b31-f6a7c87a32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture  \n",
    "## upgrade accelerate to use device_map \n",
    "!pip install --upgrade accelerate ## this is for compatability with `bitsandbytes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38a6c56-7615-4c7a-8c7b-130408ccc9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "## check accelerate version after upgrade\n",
    "import accelerate\n",
    "print(f\"Accelerate version: {accelerate.__version__}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416b5aac-5866-41ff-bedf-79203a3e1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "## upgrade torchvision\n",
    "!pip install --upgrade torchvision # if you need to upgrade torchvision run this line\n",
    "!pip install --upgrade torch #upgrade torch version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225826cc-968c-4a9c-8ddd-736ebb38cdfa",
   "metadata": {},
   "source": [
    "**Note: Restart kernel before running next cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712793a0-8260-4dfd-8116-0cedd76dc7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "Torchvision version: 0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# check versions of torch available\n",
    "import torch\n",
    "import torchvision \n",
    "\n",
    "# print versions\n",
    "print(f\"PyTorch version: {torch.__version__}\") \n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f3c47-1d14-4a0a-a994-e76db810f0ab",
   "metadata": {},
   "source": [
    "## Check if GPU is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cd6a4b-933a-4c14-963c-c2c1c90c1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# set device for PyTorch operations\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.set_device(0) # you can use a different device ID if you have multiple GPUs running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2980e-fe8e-45d5-bdc0-5c20814d2ee2",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36f01cf-04f9-4320-9f1a-7d5a8711eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba462b6-5491-4bc8-970f-539d83d93ddf",
   "metadata": {},
   "source": [
    "# Load Data from S3 Bucket on AWS -- if using AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65576a1f-a5ad-40f2-a5d4-83911f73f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import pandas as pd\n",
    "# from sagemaker import get_execution_role\n",
    "\n",
    "# # Create S3 client\n",
    "# conn = boto3.client('s3')\n",
    "\n",
    "# # S3 bucket name\n",
    "# bucket = '<your bucket here>'\n",
    "\n",
    "# # Correct data_key (remove the leading slash)\n",
    "# data_key = '<file source>/inputs/df_triplets_experiment.csv'\n",
    "\n",
    "# # Construct the full S3 URI\n",
    "# data_location = f's3://{bucket}/{data_key}'\n",
    "\n",
    "# # Load the DataFrame -->  variable is `df_qlik`\n",
    "# try:\n",
    "#     df_qlik = pd.read_csv(data_location)\n",
    "#     print(df_qlik.head())\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "    \n",
    "#     # List objects in the bucket to check if the file exists\n",
    "#     response = conn.list_objects_v2(Bucket=bucket, Prefix='<file source>/inputs/')\n",
    "    \n",
    "#     if 'Contents' in response:\n",
    "#         print(\"Files in the specified S3 location:\")\n",
    "#         for obj in response['Contents']:\n",
    "#             print(obj['Key'])\n",
    "#     else:\n",
    "#         print(\"No files found in the specified S3 location.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa96dd-d7ad-444d-950e-71cfe0d74ee8",
   "metadata": {},
   "source": [
    "# Load Data from local files if not using AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3dad4d8d-cb3f-4371-81ac-90a3a45b480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATA\n",
    "df = pd.read_csv('df_triplets_experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30ee5f9e-011a-440c-be3f-112fb58164bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_date</th>\n",
       "      <th>award_type</th>\n",
       "      <th>english_message</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Kam Wei has been instrumental in helping to cl...</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Sid is a rare Player-Coach that inspires his c...</td>\n",
       "      <td>6630 1st Line Mgr - SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Myung Soo rejoined Qlik in August 2024, but qu...</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Congrats, Sean!</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Thank you Jason for being persistent and consi...</td>\n",
       "      <td>6120 QC Sales Enterprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   award_date award_type                                    english_message  \\\n",
       "0  2025-01-01  Applaud 2  Kam Wei has been instrumental in helping to cl...   \n",
       "1  2025-01-01  Applaud 2  Sid is a rare Player-Coach that inspires his c...   \n",
       "2  2025-01-01  Applaud 2  Myung Soo rejoined Qlik in August 2024, but qu...   \n",
       "3  2025-01-01  Applaud 2                                    Congrats, Sean!   \n",
       "4  2025-01-01  Applaud 2  Thank you Jason for being persistent and consi...   \n",
       "\n",
       "                 department  \n",
       "0  6600 Solution Consultant  \n",
       "1    6630 1st Line Mgr - SC  \n",
       "2  6600 Solution Consultant  \n",
       "3  6600 Solution Consultant  \n",
       "4  6120 QC Sales Enterprise  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check df head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f8d12-c85b-40bd-b628-95425147a95c",
   "metadata": {},
   "source": [
    "# Filter data for sample testing\n",
    "* We will do this 2 ways:\n",
    "\n",
    "1. Random sample or just filter based on number of rows.\n",
    "2. Filter based on timeframe of months to a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbacfb6-8519-4dc8-871b-14559e274b4f",
   "metadata": {},
   "source": [
    "## 2. Change `award_date` to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43612dba-7fbc-4be7-9dd6-1e00e0351a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "award_date         object\n",
       "award_type         object\n",
       "english_message    object\n",
       "department         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dtypes checks\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a92d166-ec7e-49ed-9c8a-0837793021ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# convert `date` to datetime format for filtering\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b931fc4-c266-4361-9b85-994393342a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "award_date         datetime64[ns]\n",
       "award_type                 object\n",
       "english_message            object\n",
       "department                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check dtypes again\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa101cf7-42c7-40e2-a44d-dfdf4a55a4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15908   2024-02-06\n",
       "Name: award_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## view sample of award_date\n",
    "df['date'].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020a3a5-aeeb-4fa3-b2f1-dfc2959cfca2",
   "metadata": {},
   "source": [
    "## 3. Filter based on specific date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1774e87b-0051-4c84-9115-57d657d852e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-02 00:00:00')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "809471e9-1534-4a3f-946c-9354efd9d70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-01-01 00:00:00')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "617c9568-9cf3-4de9-9242-075b8dbc0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def filter_date_range(df, start_date=None, end_date=None, n_months=None):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame based on a date range.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to filter\n",
    "    start_date (str or datetime): The start date of the range (inclusive)\n",
    "    end_date (str or datetime): The end date of the range (inclusive)\n",
    "    n_months (int): Number of months to look back from end_date (if start_date is not provided)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Filtered DataFrame\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If end_date is not provided, use the current date\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now()\n",
    "    elif isinstance(end_date, str):\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    # If start_date is not provided, calculate it based on n_months\n",
    "    if start_date is None:\n",
    "        if n_months is None:\n",
    "            raise ValueError(\"Either start_date or n_months must be provided\")\n",
    "        start_date = end_date - pd.DateOffset(months=n_months)\n",
    "    elif isinstance(start_date, str):\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "    \n",
    "    # Ensure the date column is in datetime format\n",
    "    df.loc[:, 'date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    filtered_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94693dcf-62eb-4ae2-9acd-072318235367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in last 6 months from 2018-06-12: 2260\n",
      "Number of records between 2018-01-01 and 2018-06-12: 2260\n",
      "Number of records in last 6 months from today: 8086\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Filter data for the last 6 months from a specific end date\n",
    "df_last_6_months = filter_date_range(df, n_months=6, end_date='2018-06-12')\n",
    "\n",
    "# Filter data between two specific dates\n",
    "df_specific_range = filter_date_range(df, start_date='2018-01-01', end_date='2018-06-12')\n",
    "\n",
    "# Filter data for the last 6 months from today\n",
    "df_recent_6_months = filter_date_range(df, n_months=6)\n",
    "\n",
    "print(f\"Number of records in last 6 months from 2018-06-12: {len(df_last_6_months)}\")\n",
    "print(f\"Number of records between 2018-01-01 and 2018-06-12: {len(df_specific_range)}\")\n",
    "print(f\"Number of records in last 6 months from today: {len(df_recent_6_months)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ba7bb39-0b6e-4f38-8508-ff12e43b1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying both start and end dates\n",
    "df_2_weeks = filter_date_range(df, start_date='2024-10-15', end_date='2024-10-20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27737c66-0e29-44fa-b805-61c43e3c5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in 2 weeks : 356\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records in 2 weeks : {len(df_2_weeks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bed5a-c3e0-466a-a590-df36849d8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using n_months and end_date (similar to your original function)\n",
    "# df_range1 = filter_date_range(df, n_months=6, end_date='2018-06-12')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95aca3-2fb2-47be-b20b-d35dc1fc8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using n_months from today\n",
    "# df_range3 = filter_date_range(df, n_months=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2306ec2-ace1-463b-96d3-e492d260e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using start_date and n_months\n",
    "# df_range4 = filter_date_range(df, start_date='2018-01-01', n_months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312e518-91c8-4e24-b6f3-9c630a507294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f487f7-3709-4a54-b255-ef7b52f8d9dd",
   "metadata": {},
   "source": [
    "# Hugging Face Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "603fa7b4-f81b-4ca5-b984-08af6e9fe429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0c23576c0b4b0990a015f78c72b042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## hf hub login\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc2ff2-b229-4983-a27d-9d41d88488fe",
   "metadata": {},
   "source": [
    "# Skills & Behavior Processing Script using Gemma-2-9b-It LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "835e091d-1886-42e5-b67e-ae96e301907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillBehaviorProcessor:\n",
    "    def __init__(self, model_name=\"google/gemma-2-9b-it\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Quantization configuration\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "        \n",
    "        # Load model\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "\n",
    "        # Initialize Accelerator\n",
    "        self.accelerator = Accelerator()\n",
    "        self.model = self.accelerator.prepare(self.model)\n",
    "\n",
    "    def generate_text(self, prompt, max_new_tokens=256):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def generate_pseudo_label(self, text):\n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "Given the following text, identify and extract key phrases related to work behaviors, hard skills, and soft skills demonstrated. Use a step-by-step approach:\n",
    "\n",
    "Text: \"{text}\"\n",
    "\n",
    "Step 1: Identify potential work behaviors, hard skills, and soft skills mentioned in the text.\n",
    "Step 2: For each identified item, determine if it's a work behavior, hard skill, or soft skill.\n",
    "Step 3: Formulate concise phrases for each work behavior, hard skill, and soft skill.\n",
    "Step 4: List the work behaviors, hard skills, and soft skills separately.\n",
    "\n",
    "Output the results in the following format:\n",
    "\n",
    "Work Behaviors:\n",
    "[List work behaviors here, one per line. If none found, write \"No behaviors found.\"]\n",
    "\n",
    "Hard Skills:\n",
    "[List hard skills here, one per line. If none found, write \"No hard skills found.\"]\n",
    "\n",
    "Soft Skills:\n",
    "[List soft skills here, one per line. If none found, write \"No soft skills found.\"]\n",
    "\n",
    "If no behaviors or skills are found at all, output \"None found.\" for each category.\n",
    "\n",
    "Here are two examples:\n",
    "\n",
    "Example 1:\n",
    "Text: \"John consistently meets deadlines and delivers high-quality work. He's proficient in Python and SQL, and always communicates clearly with team members.\"\n",
    "\n",
    "Work Behaviors:\n",
    "Meets deadlines consistently\n",
    "Delivers high-quality work\n",
    "\n",
    "Hard Skills:\n",
    "Python proficiency\n",
    "SQL proficiency\n",
    "\n",
    "Soft Skills:\n",
    "Clear communication\n",
    "\n",
    "Example 2:\n",
    "Text: \"Thank you for your hard work this quarter.\"\n",
    "\n",
    "Work Behaviors:\n",
    "No behaviors found.\n",
    "\n",
    "Hard Skills:\n",
    "No hard skills found.\n",
    "\n",
    "Soft Skills:\n",
    "No soft skills found.\n",
    "\n",
    "Now, please analyze the provided text and output the results in the same format.\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "\n",
    "        return self.generate_text(prompt)\n",
    "    \n",
    "\n",
    "    def classify_behaviors_and_skills(self, behaviors, hard_skills, soft_skills):\n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "Given the following work behaviors, hard skills, and soft skills, classify them into general categories:\n",
    "\n",
    "Work Behaviors: {behaviors}\n",
    "Hard Skills: {hard_skills}\n",
    "Soft Skills: {soft_skills}\n",
    "\n",
    "Provide a general classification for the behaviors, hard skills, and soft skills. Output the results in the following format:\n",
    "Behavior Class: [General category for behaviors, or \"None\" if no behaviors]\n",
    "Hard Skill Class: [General category for hard skills, or \"None\" if no hard skills]\n",
    "Soft Skill Class: [General category for soft skills, or \"None\" if no soft skills]\n",
    "\n",
    "If there are neither skills nor behaviors found, output \"None\" for all categories.\n",
    "\n",
    "Here are two examples:\n",
    "\n",
    "Example 1:\n",
    "Work Behaviors: Meets deadlines consistently, Delivers high-quality work\n",
    "Hard Skills: Python proficiency, SQL proficiency\n",
    "Soft Skills: Clear communication\n",
    "\n",
    "Output:\n",
    "Behavior Class: Time Management and Quality Assurance\n",
    "Hard Skill Class: Programming and Database Management\n",
    "Soft Skill Class: Communication\n",
    "\n",
    "Example 2:\n",
    "Work Behaviors: No behaviors found.\n",
    "Hard Skills: No hard skills found.\n",
    "Soft Skills: No soft skills found.\n",
    "\n",
    "Output:\n",
    "Behavior Class: None\n",
    "Hard Skill Class: None\n",
    "Soft Skill Class: None\n",
    "\n",
    "Now, please classify the provided behaviors and skills in the same format.\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "\n",
    "        return self.generate_text(prompt)\n",
    "    \n",
    "    \n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        with tqdm(total=3, desc=\"Batch processing steps\", leave=False) as pbar:\n",
    "            pseudo_labels = [self.generate_pseudo_label(text) for text in batch['english_message']]\n",
    "            pbar.update(1)\n",
    "        \n",
    "            work_behaviors, hard_skills, soft_skills = zip(*[self.extract_skills_and_behaviors(label) for label in pseudo_labels])\n",
    "            pbar.update(1)\n",
    "        \n",
    "            classifications = [self.classify_behaviors_and_skills(b, h, s) for b, h, s in zip(work_behaviors, hard_skills, soft_skills)]\n",
    "            behavior_class, hard_skill_class, soft_skill_class = zip(*[self.extract_classifications(c) for c in classifications])\n",
    "            pbar.update(1)\n",
    "        return pd.DataFrame({\n",
    "            'work_behaviors': work_behaviors,\n",
    "            'hard_skills': hard_skills,\n",
    "            'soft_skills': soft_skills,\n",
    "            'behavior_class': behavior_class,\n",
    "            'hard_skill_class': hard_skill_class,\n",
    "            'soft_skill_class': soft_skill_class\n",
    "        })\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_skills_and_behaviors(text):\n",
    "        work_behaviors, hard_skills, soft_skills = [], [], []\n",
    "        current_category = None\n",
    "        for line in text.split('\\n'):\n",
    "            if line.startswith('Work Behaviors:'):\n",
    "                current_category = 'behaviors'\n",
    "            elif line.startswith('Hard Skills:'):\n",
    "                current_category = 'hard_skills'\n",
    "            elif line.startswith('Soft Skills:'):\n",
    "                current_category = 'soft_skills'\n",
    "            elif line.strip().startswith(('1.', '2.', '3.')):\n",
    "                item = line.split('.', 1)[1].strip()\n",
    "                if current_category == 'behaviors':\n",
    "                    work_behaviors.append(item)\n",
    "                elif current_category == 'hard_skills':\n",
    "                    hard_skills.append(item)\n",
    "                elif current_category == 'soft_skills':\n",
    "                    soft_skills.append(item)\n",
    "        return ', '.join(work_behaviors), ', '.join(hard_skills), ', '.join(soft_skills)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_classifications(classifications):\n",
    "        behavior_class = hard_skill_class = soft_skill_class = ''\n",
    "        for line in classifications.split('\\n'):\n",
    "            if line.startswith('Behavior Class:'):\n",
    "                behavior_class = line.split(':', 1)[1].strip()\n",
    "            elif line.startswith('Hard Skill Class:'):\n",
    "                hard_skill_class = line.split(':', 1)[1].strip()\n",
    "            elif line.startswith('Soft Skill Class:'):\n",
    "                soft_skill_class = line.split(':', 1)[1].strip()\n",
    "        return behavior_class, hard_skill_class, soft_skill_class\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def process_dataframe(self, df, max_batch_size=32):\n",
    "        total_batches = (len(df) + max_batch_size - 1) // max_batch_size\n",
    "    \n",
    "        with tqdm(total=total_batches, desc=\"Processing batches\") as pbar:\n",
    "            for i in range(0, len(df), max_batch_size):\n",
    "                batch = df.iloc[i:i+max_batch_size]\n",
    "                batch_results = self.process_batch(batch)\n",
    "            \n",
    "                # Update the original dataframe with new columns\n",
    "                for col in batch_results.columns:\n",
    "                    df.loc[df.index[i:i+max_batch_size], col] = batch_results[col].values\n",
    "            \n",
    "                pbar.update(1)\n",
    "    \n",
    "        return df  # Return the updated original dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6120bf-b8e6-4eef-9a8b-f1d4dba6247b",
   "metadata": {},
   "source": [
    "# Run `SkillBehaviorProcessor` Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abec78b3-a9ce-4562-98a2-5b54c6f2bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_date</th>\n",
       "      <th>award_type</th>\n",
       "      <th>english_message</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Kam Wei has been instrumental in helping to cl...</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Sid is a rare Player-Coach that inspires his c...</td>\n",
       "      <td>6630 1st Line Mgr - SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Myung Soo rejoined Qlik in August 2024, but qu...</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Congrats, Sean!</td>\n",
       "      <td>6600 Solution Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Applaud 2</td>\n",
       "      <td>Thank you Jason for being persistent and consi...</td>\n",
       "      <td>6120 QC Sales Enterprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  award_date award_type                                    english_message  \\\n",
       "0 2025-01-01  Applaud 2  Kam Wei has been instrumental in helping to cl...   \n",
       "1 2025-01-01  Applaud 2  Sid is a rare Player-Coach that inspires his c...   \n",
       "2 2025-01-01  Applaud 2  Myung Soo rejoined Qlik in August 2024, but qu...   \n",
       "3 2025-01-01  Applaud 2                                    Congrats, Sean!   \n",
       "4 2025-01-01  Applaud 2  Thank you Jason for being persistent and consi...   \n",
       "\n",
       "                 department  \n",
       "0  6600 Solution Consultant  \n",
       "1    6630 1st Line Mgr - SC  \n",
       "2  6600 Solution Consultant  \n",
       "3  6600 Solution Consultant  \n",
       "4  6120 QC Sales Enterprise  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check df using\n",
    "df_1_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37ba3f3e-b096-4684-8f34-57db1cd1c17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06508c0-58dd-45dd-904b-26ea4ff2f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "processor = SkillBehaviorProcessor()\n",
    "\n",
    "# Process the DataFrame with overall progress bar\n",
    "total_rows = len(df_2_weeks)\n",
    "with tqdm(total=total_rows, desc=\"Overall progress\") as pbar:\n",
    "    df_2_weeks = processor.process_dataframe(df_2_weeks, max_batch_size=32)\n",
    "    pbar.update(total_rows)\n",
    "\n",
    "# df now contains the original columns plus the new columns\n",
    "\n",
    "# Display sample results\n",
    "print(df_2_weeks[['english_message', 'work_behaviors', 'hard_skills', 'soft_skills', 'behavior_class', 'hard_skill_class', 'soft_skill_class']].head())\n",
    "\n",
    "# Save the results\n",
    "df_2_weeks.to_csv('2_weeks_Qlik_processed_results.csv', index=False)\n",
    "print(\"Results saved to 2_weeks_Qlik_processed_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
